% Some commands used in this file
\newcommand{\package}{\emph}

\chapter{Introduction}
\label{chap:introduction}

Blabla

\section{Features}
\label{sec:features}
The template is divided into \TeX{} files as follows:
\begin{enumerate}
\item \texttt{thesis.tex} is the main file.
\item Here we introduce the ToxCast pipeline (tcpl), a
    novel R extension (R Core Team, 2016), to provide storage,
    normalization, dose–response modeling and visualization solutions
    for HTS screening efforts.tcpl provides functionality to identify potentially active compounds (positive hit-calls) for both single- and
    multiple-concentration testing paradigms. Multiple-concentration
    processing also includes dose-response modeling to give potency and
    efficacy estimates, and categorization of each concentration series to
    better identify potential false positive and false negative results.
    \item 
    Often controversial uncertainty factors
    must be applied to account for differences
    between test animals and humans. Finally,
    use of animals in testing is expensive and
    time consuming, and it sometimes raises
    ethical issues.
    \item Tropsha10demonstrated that the presence orabsence of structural errors in a library and the choice of descriptors had agreater impact on performance than model optimization. Hence, there is aneed to pay attention to systematic chemical curation protocols prior tomodeling. Fourche et al.14provide a reproducible workflow for cleaning upchemical data prior to developing a model.
    \item Regardless of how generalized a model may appear to be following valid-ation, it is impractical to consider the model applicable to the entire chem-ical space. The predictions made by models on new compounds withdescriptor values outside the training data descriptor (feature) space maynot be reliable. It is therefore necessary to know the boundary withinwhich the model can extrapolate reliably. The applicability domain (AD) defines the scope and limitations of a model. AD attempts to define thedegree of generalization of the model by highlighting the range of chemicalstructures for which the model is considered to be reliably applicable.94,95Predictions  of  compounds  outside  a  models  AD  cannot  be  consid-ered reliable.
    \item Distance-based  methods  use  distance  measures  (e.g.  Tanimoto  or Euclidean) to calculate the distance between a new compound and its k-nearest neighbors (or the centroid of the training set). A threshold, basedon distance, is used to determine if the new compound is within the ADor not. Predictions of any compound beyond the threshold are consideredto be unreliable. The downside of this method is that the threshold value isoften arbitrary. Using the Enalos module, KNIME provides a graphicaluser interface to generate the AD domain based on Euclidean Distance andLeverage. One other type of non-descriptor method is the structural fragment-based method, which requires that all structural fragments in the newmolecule be present in the training set.
    \item Ensemble learners coupledwith resampling include UnderBagging, 77SMOTEBagging, 78SMOTEBoost,79 and EUSBoost80 (which is considered an improvement over RUSBoost).
    \item Metrics such as Accuracyand even AUROC tend to be rather optimistic82when dealing with180G. IDAKWO ET AL.imbalanced data. AUPRC and other metrics such as Balanced Accuracy,Sensitivity, and Specificity appear to provide a better or at least comple-mentary evaluation for imbalanced classifiers
    \item With the large number of available descriptors,26datasets often suffer fromthe“curse of dimensionality (problems caused by performing predictionsin a very large feature space) and the so-called“large p, small n
    \item Models with fewer descriptors are easier to interpret, lesscomputationally expensive, higher performing for new molecules, and lessprone to overfitting/overtraining
    \item In other words, models trained on a very small set of molecules that aredescribed with a very large set of descriptors tend to be prone to overfit-ting.37An overfitted model can mistake small fluctuations for importantvariance in the data, which can result in significant prediction errors.Identifying reliable descriptors for establishing this relationship can pose aserious challenge.
    \item The process does not alter the original repre-sentation of the descriptors, thus maintaining the physical meanings andallowing for interpretability
    \item Feature selection involves picking a subset of features by eliminatingirrelevant and redundant descriptors, yielding the best possible performancebased on a selection criterion. The process does not alter the original repre-sentation of the descriptors, thus maintaining the physical meanings andallowing for interpretability. Feature selection techniques can be classifiedinto filter, wrapper, and embedded methods.26,40,41Filters work withouttaking the classifier into consideration. They rely on measures of the gen-eral characteristics of the training data,
    \item Multiple fingerprint predictions were obtained for one chemical if both negative and positive mode spectra were available or by different research groups or with different LC-HRMS parameters. For validation, fingerprints were calculated using SIRIUS+CSI:FingerID version 4.9.5. (41,42) All of the chosen parameters for SIRIUS+CSI:FingerID are described in the SI section “Fingerprints Calculated with SIRIUS Software”. https://pubs.acs.org/doi/full/10.1021/acs.est.2c02536
    \item The US EPA ToxCast program generates high-throughput screening (HTS) bioactivity data for use in various predictive toxicology applications 32, 35. The ToxCast data pipeline (tcpl) [17] has been used to normalize and curve-fit data for nearly 1400 assay end points, thus enabling first-tier data processing of heterogeneous bioactivity data from HTS. For each chemical sample:assay end point pair with at least 4 concentrations available, the tcpl curve-fitting procedure attempts to fit a Hill, a gain-loss, and a constant model, with the model selection based on a maximum likelihood estimate [17]. The tcpl analysis generates concentration–response parameters on the basis of the winning model, including the 50 percent activity concentration (AC50), the potency estimate. There are multiple sources of potential variability in these AC50s, resulting from biological variance, experimental error, or curve-fitting procedures. One method for quantifying uncertainty in ToxCast curve-fitting is called toxboot, an R package extension of tcpl that implements smooth nonparametric bootstrapping (a statistical method that uses resampling and added noise to determine uncertainty in a series) 76, 77. This addition of random, normally distributed noise to the series allows one to be more confident in the winning model if similar models are produced in each iteration. By resampling and adding normally distributed noise over many iterations, a general picture of the confidence in a curve fit can be ascertained. Two examples of the quantitative measures of uncertainty produced by toxboot are hit percent and an AC50 confidence interval. Hit percent is the number of active hit-calls of the total number of resamples, currently with 1000 resamples per curve. This is potentially informative because the binary hit-call for a borderline response, positive or negative, is particularly susceptible to minor fluctuations in the data, especially for weak or borderline responses. With a more continuous statistic (ranging from 0 to 1), such as hit-call percent, the borderline hit-calls may be more obvious; currently, roughly 61 percent of positive hit-calls (hitcall equals 1) correspond to a hit percent of 100 in the latest ToxCast database release [16]. Additionally, tcpl can be executed upon each resampled set and generate an AC50 (or AC10, AC20, area under the curve, etc.) and further generate a median value and a 95 percent confidence interval, on the basis of the results. These approaches could be used as a method to determine the confidence in potency estimates derived from concentration series. A summary of curve-fitting uncertainty information is available in level 7 of the latest ToxCast database release, invitrodb version 3.1 [16].
    \item The issue of quantitative uncertainty in fitting in vitro activity data is not unique to ToxCast data, and different approaches have been developed to handle this uncertainty. Previously, the US EPA's Benchmark Dose software, used commonly in modeling dose–response information from in vivo toxicity studies to define PODs, has been adapted for use in modeling gene expression data sets as BMDExpress 3, 82. BMDExpress enables automated analysis of continuous transcriptomic data via identification of genes that demonstrate significant dose–response behavior, followed by curve-fitting with statistical models that can be used to define a confidence interval around a potency estimate for significant changes in expression for a given gene. The upper and lower bounds on the confidence interval for a BMD thus give a sense of the uncertainty in fitting the available transcriptomic data. A commonality between the BMDExpress and toxboot approaches, both suited to HTS data of different types, is the desire to communicate a confidence interval around the potency estimate. BMDExpress is flexible in that the upper and lower bounds (BMDU and BMDL, respectively) of the confidence interval around a calculated potency value can be modified, allowing for differing levels of uncertainty in the analysis. Using default parameters, for a differentially expressed gene, BMDExpress will calculate a 95 percent confidence interval around a BMD for a 10 percent increase or decrease in response compared to the background of the control samples.
    \item Among the challenges are feature selection among potentially large numbers of correlated features; approaches to model evaluation; limited domain of applicability; and handling imbalanced training data, wherein the ML model learns from a dataset containing many examples of one type of outcome, but only a few examples of another type.
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
    \item
\end{enumerate}
