\chapter{Discussion}\label{chap:discussion}

When it comes to prioritizing compound identification in environmental samples through hazard assessment, the objective is to maximize the likelihood of detecting toxic substances while simultaneously minimizing predictions that result in false alarms which represent non-hazardous compounds misclassified as toxic. 

Dealing with highly imbalanced datasets, coupled with a vast chemical space that is assumed to be sparsely represented in the limited training dataset, can present a challenging task for achieving robust predictive performance. Nonetheless, the results demonstrate that the developed pipeline is capable of predicting toxicity based on molecular fingerprints derived from chemical structure. However, the model performances obtained on unweighted class metrics are relatively modest, and we were unable to validate the reported balanced accuracy of 0.75 as found in~\cite{arturi}. This inconsistency may be attributed to the fact that the set of assay endpoints as well as the drawn training sets are not a perfect match. 

In the case of the internal validation set, consider Figure~\ref{fig:hitcall_classification_Feature_Selection_XGBClassifier_val_tpr_macro_avg}, where a macro-averaged metric with a particular threshold that fixes the true positive rate to approximately 0.5 is employed. The XGBoost classifier attains a median F1-score of 0.65 and balanced accuracy of 0.61 over 345 target assay endpoints in total. The performance of the multi-layer perceptron (MLP) was found to be disappointing and can be ascribed to the constraints imposed by the limited volume of data available for training a neural network.

The slight decline in model performance for the MassBank validation set based on chemical fingerprints from structure can be explained by the fact that the MassBank validation set's target variable distribution is not a perfect match with that of the training set, in contrast to the internal stratified validation set, which mirrors the training set's distribution. For future work, a more in-depth analysis of the compounds within the MassBank validation set can shed light on any potential bias in the chemical space it covers. Additionally, it's important to note that the MassBank validation set is relatively small based on specific assay endpoints, which may contribute to increased variability in the model's performance. The mdeian model performances assessed on the MassBank validation set using SIRIUS-predicted fingerprints show a marginal dip compared to those relying on chemical fingerprints derived from the molecular structure. This is an encouraging result, as it demonstrates that the developed pipeline is capable of predicting toxicity based on predicted fingerprints from spectral data.

Importantly, the results emphasize the crucial importance of the chosen classification threshold paired with the employed class metric (macro average, weighted average, positive, negative) in achieving this balance, especially when dealing with such imbalanced toxicity datasets. As an example, please refer to Figure~\ref{fig:hitcall_classification_Feature_Selection_XGBClassifier_val_default_macro_avg}, where the sensitivity of the random forest classifier to the threshold is clearly evident. Notably, when employing the default threshold of 0.5, the random forest classifier exhibits a lower median F1-score compared to the logistic regression classifier which tends to be more robust to threshold variations due to its inherent probabilistic nature. However, when considering alternative thresholds, the random forest classifier outperforms the logistic regression classifier in terms of F1-score. This sensitivity can be attributed to the highly imbalanced data. 

In practical application of these models, selecting an ideal threshold depends on the laboratory's specific prioritization goals and resource constraints. This decision should take into account the sample size and the level of false alarms that can be tolerated, particularly if all positive predicted instances are pipelineed for an early-stage filtering process. In cases where prioritization aims to capture as many toxic compounds as possible, the threshold should be configured such that the true positive rate (TPR) takes precedence over the true negative rate (TNR). We explicitly examined a scenario (e.g., Figure~\ref{fig:hitcall_classification_Feature_Selection_XGBClassifier_val_default_macro_avg}) in which TPR was given twice the weight of TNR, resulting in the detection of more toxic compounds but also incurring a higher number of false alarms. On the other hand, when laboratory testing resources are limited, setting a higher threshold may be preferable. While this mitigates the number of false alarms, it comes with the cost of a reduction in the number of detected toxic compounds.

The analysis of fingerprint feature importance, as documented in Section~\ref{sec:feature_importance}, revealed a noteworthy finding supported by two independent models (XGBoost and random forest classsifier), emphasizing the idea that the existence or absence of specific molecular substructures encodes substantial toxicity information. We found substantial fingerprint features appearing in both models in the top 10 features. This discovery holds great promise, as it offers a pathway to understand the models' predictions and to delve into the biochemical mechanisms underlying toxicity. In the scope of this work, we ommited to map the relative feature indices back to the absolute index of the molecular fingerprint types. This aspect can be taken into account for future research when investigating alternative feature selection strategies or when aiming to create visual representations of the most informative chemical substructures. 





