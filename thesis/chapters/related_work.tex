\chapter{Related work}\label{chap:related_work}

Recent advancements in ML-based prediction of toxicity endpoints, were summarized in~\cite{cavasotto2022} and it was found that teh progresses are driven primarily by the efforts in drug discovery. 

The recent developments in machine learning for predicting toxicity endpoints were outlined in~\cite{cavasotto2022}, with an observation that these advancements are primarily driven by the progress made in the field of drug discovery. The study underscores that machine learning approaches demonstrate varying performance levels across diverse toxicity endpoints, with commonly studied ones including cardiotoxicity, mutagenicity, hepatotoxicity and acute oral toxicity,but also those endpoints from the popular Tox21 data challenge~\cite{richard2021}. The ability to predict toxicity depends significantly on the characteristics of the datasets, including differences in complexity, class distribution, and the chemical space they encompass, making it challenging to directly compare algorithm performance.

A recent study~\cite{kretschmer2023} explores the coverage of large-scale datasets used in machine learning for biomolecular structures, revealing their limitations in representing the full range of known structures. As the chemical space is vast, it is questionable whether the toxicity training data is an informative subset to the true distribution aimed to learn, directly challenging the fundamental assumption in machine learning. The study underscores the importance of taking into account the coverage of chemical space when assessing the effectiveness of machine learning models. In this thesis, the coverage of the chemical space was not specifically assessed, as the focus was on the performance of the models and their ability to generalize to unseen data.

Similar to MLinvitroTox, MS2Tox~\cite{peets2022} represents another machine learning approach within the realm of predicting ecotoxicological hazards for unidentified compounds through nontarget HRMS/MS analysis. Both approaches adopt a common strategy of building their ML models based on molecular fingerprints derived from chemical structure, used to make predictions on environmental samples, utilizing fingerprints from fragmentation spectra calculated by SIRIUS+CSI:FingerID. However, ML2Tox diverges in terms of the toxicity data employed for training and testing, with its focus on toxicity data concerning \emph{in vivo} fish lethal concentrations from CompTox~\cite{williams2017}. This is in contrast to MLinvitroTox, which relies on \emph{in vitro} toxicity data from ToxCast/Tox21. Additionally, unlike MLinvitroTox, which exclusively relies on molecular fingerprints and does not utilize other physicochemical properties, MS2Tox incorporates the molecular mass of the compound as an additional feature.

In a systematic investigation using Tox21 data~\cite{wu2021}, the impact of various modeling approaches on predictive toxicology were explored, with a focus on model performance and explainability trade-offs. The study found that endpoints with higher predictability, characterized by lower data imbalance and larger datasets, performed well regardless of the modeling approach or molecular representation. For less predictable endpoints, simpler models like Linear Regression performed similarly to complex ones, thereby emphasizing the importance of balancing predictability and interpretability. Moreover this study suggests consensus modeling and multi-task learning to enhance predictability and model performance across endpoints. In this thesis, the goal was established to not to overlook simpler models due to their higher interpretability and comparable performance. As recommended, no further explorations were conducted regarding the various molecular representations, and instead, a fixed set of molecular fingerprints was employed as the initial input features, with feature selection being applied to reduce the number of relevant features. Furthermore, a consensus modeling approach was adopted, where the final predictions are obtained by averaging the predictions across assay endpoints sharing the same attributes, including mechanistic and biological target.